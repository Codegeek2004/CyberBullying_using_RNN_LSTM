# -*- coding: utf-8 -*-
"""7_Text_Prediction_RNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pjA0o9PtRzDqMMrLgJlBXpSOBYAZhB4u
"""

#pip install contractions emoji
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'

import re
import contractions
import emoji
import nltk
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt_tab')
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize

#pip install tensorflow

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    text = text.lower()  # Lowercasing
    text = contractions.fix(text)  # Expanding contractions
    text = re.sub(r'http\S+|www\S+|https\S+', '', text)  # Removing URLs
    text = re.sub(r'\@\w+|\#','', text)  # Removing mentions and hashtags
    text = emoji.demojize(text)  # Converting emojis to text
    text = re.sub(r'_', ' ', text) # Removing underscore from the description of the emojis
    text = re.sub(r'[^\w\s]', '', text)  # Removing special characters
    text = re.sub(r'\d+', '', text)  # Removing digits
    text = word_tokenize(text)
    text = ' '.join([word for word in text if word not in stop_words])  # Removing stopwords
    text = ''.join([lemmatizer.lemmatize(word) for word in text])  # Lemmatization
    return text

# text = "I'm so tired of this! ðŸ˜¡ Check this out: https://example.com #frustrated"
# text = "Go back to where you came from, you're not welcome here."
# text = "Youâ€™re such a failure, itâ€™s embarrassing to watch."
# text = "I donâ€™t agree with your opinion, but I respect it."

import pickle
from tensorflow.keras.models import load_model

# Load the model
model = load_model('rnn_model.keras')

with open('tokenizer_rnn.pkl', 'rb') as f:
    tokenizer = pickle.load(f)

from tensorflow.keras.preprocessing.sequence import pad_sequences

# Function to preprocess and predict the input text
def predict_cyberbullying(text):
    # Clean the text (if you have a cleaning function, use it here)
    cleaned_text = text.lower()  # Simple example of cleaning

    # Convert the cleaned text into sequences using the tokenizer
    text_sequence = tokenizer.texts_to_sequences([cleaned_text])

    # Pad the sequences to ensure they match the expected input shape
    padded_text = pad_sequences(text_sequence, maxlen=100, padding='pre', truncating='post')

    # Predict using the loaded model
    prediction = model.predict(padded_text)

    # Return the prediction (example: 1 = cyberbullying, 0 = not)
    return "Cyberbullying" if prediction[0] > 0.5 else "Not Cyberbullying"

if __name__ == "__main__":
    user_input = input("Enter the comment: ")
    result = predict_cyberbullying(user_input)
    print(result)