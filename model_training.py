# -*- coding: utf-8 -*-
"""Model_Training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1viAYxRQJxJNvOrd96gOvKxqM4rFlZJnv
"""

#pip install scikit-learn

from google.colab import files
uploaded = files.upload()

import pandas as pd
#df = pd.read_csv('preprocessed_1000_automated.csv')
#df = pd.read_csv('preprocessed_2000_automated.csv')
df = pd.read_csv('preprocessed(1000).csv')
#df = pd.read_csv('preprocessed(2000).csv')
df.head(10)

df.info()

uploaded = files.upload()

#df2 = pd.read_csv('classification_1000_automated.csv')
#df2 = pd.read_csv('classification_2000_automated.csv')
df2 = pd.read_csv('classification(1000).csv')
#df2 = pd.read_csv('classification(2000).csv')
print(df2.head(10))

new_df = pd.DataFrame({
    'new_comments': df['new_comments'],
    'classification': df2['classification']
})
new_df2 = new_df.dropna(subset=['new_comments'])
df3 = new_df2.dropna(subset=['classification'])

df3.head(10)

#df3.to_csv('filename.csv', index=False)

print(len(df3))

from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.feature_extraction.text import TfidfVectorizer


x = df3['new_comments']
y = df3['classification']

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)

X_train.head()

y_train.head()

print(y_train.value_counts())

X_test.head()

y_test.value_counts()

import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer  # Import TfidfVectorizer


# Create a TfidfVectorizer to convert text to numerical features
vectorizer = TfidfVectorizer()

# Fit the vectorizer to your training data and transform it
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec=vectorizer.transform(X_test)

import pickle
with open('vectorizer.pkl','wb') as file:
  pickle.dump(vectorizer,file)

from google.colab import files
files.download('vectorizer.pkl')

X_train_vec.shape,X_test_vec.shape

"""LOGISTIC REGRESSION"""

# Now use the transformed data for training
lr = LogisticRegression(max_iter=1000, solver='lbfgs')
lr.fit(X_train_vec, y_train)

y_pred=lr.predict(X_test_vec)
pred_df=pd.DataFrame(data={'tested_comments':X_test,'y_predicted':y_pred,'y_actual':y_test})
pred_df.head()

from sklearn.metrics import confusion_matrix,classification_report
y_actul_arr=np.array(y_test)
y_pred_arr=np.array(y_pred)
cm=confusion_matrix(y_actul_arr,y_pred_arr)

import seaborn as sns
import matplotlib.pyplot as plt
sns.heatmap(cm,
            annot=True,
            fmt='g',
            xticklabels=['cyberbullying','Not cyberbullying'],
            yticklabels=['cyberbullying','Not cyberbullying'])
plt.ylabel('Actual', fontsize=13)
plt.title('Confusion Matrix', fontsize=17, pad=20)
plt.gca().xaxis.set_label_position('top')
plt.xlabel('Prediction', fontsize=13)
plt.gca().xaxis.tick_top()

plt.gca().figure.subplots_adjust(bottom=0.2)
plt.gca().figure.text(0.5, 0.05, 'Prediction', ha='center', fontsize=13)
plt.show()

print(classification_report(y_actul_arr, y_pred_arr))

from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_pred)

"""**RANDOM FOREST CLASSIFIER**"""

from sklearn.ensemble import RandomForestClassifier
rfc=RandomForestClassifier()
rfc.fit(X_train_vec,y_train)

y_rfc_pred=rfc.predict(X_test_vec)
y_rfc_pred_arr=np.array(y_rfc_pred)
cm=confusion_matrix(y_actul_arr,y_rfc_pred_arr)

import seaborn as sns
import matplotlib.pyplot as plt
sns.heatmap(cm,
            annot=True,
            fmt='g',
            xticklabels=['cyberbullying','Not cyberbullying'],
            yticklabels=['cyberbullying','Not cyberbullying'])
plt.ylabel('Actual', fontsize=13)
plt.title('Confusion Matrix', fontsize=17, pad=20)
plt.gca().xaxis.set_label_position('top')
plt.xlabel('Prediction', fontsize=13)
plt.gca().xaxis.tick_top()

plt.gca().figure.subplots_adjust(bottom=0.2)
plt.gca().figure.text(0.5, 0.05, 'Prediction', ha='center', fontsize=13)
plt.show()

accuracy_score(y_test, y_rfc_pred)

"""**NAIVE BAYERS CLASSIFICATION**

USING MULTINOMIALNB
"""

from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer

mnb = MultinomialNB()
mnb.fit(X_train_vec, y_train)

y_mnb_pred = mnb.predict(X_test_vec)
# Convert predictions and actual labels to NumPy arrays (if needed)
y_mnb_arr = np.array(y_mnb_pred)
y_test_arr = np.array(y_test)  # Ensure y_test is also a NumPy array
# Calculate the confusion matrix
cm = confusion_matrix(y_test_arr, y_mnb_arr)

import seaborn as sns
import matplotlib.pyplot as plt
sns.heatmap(cm,
            annot=True,
            fmt='g',
            xticklabels=['cyberbullying','Not cyberbullying'],
            yticklabels=['cyberbullying','Not cyberbullying'])
plt.ylabel('Actual', fontsize=13)
plt.title('Confusion Matrix', fontsize=17, pad=20)
plt.gca().xaxis.set_label_position('top')
plt.xlabel('Prediction', fontsize=13)
plt.gca().xaxis.tick_top()

plt.gca().figure.subplots_adjust(bottom=0.2)
plt.gca().figure.text(0.5, 0.05, 'Prediction', ha='center', fontsize=13)
plt.show()

accuracy_score(y_test, y_mnb_pred)

"""**DECISION TREE**"""

from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.metrics import accuracy_score, mean_squared_error

dtc = DecisionTreeClassifier(random_state=42)
dtc.fit(X_train_vec, y_train)

y_dtc_pred = dtc.predict(X_test_vec)
y_dtc_arr = np.array(y_dtc_pred)
y_test_arr = np.array(y_test)  # Ensure y_test is also a NumPy array
cm = confusion_matrix(y_test_arr, y_dtc_arr)

import seaborn as sns
import matplotlib.pyplot as plt
sns.heatmap(cm,
            annot=True,
            fmt='g',
            xticklabels=['cyberbullying','Not cyberbullying'],
            yticklabels=['cyberbullying','Not cyberbullying'])
plt.ylabel('Actual', fontsize=13)
plt.title('Confusion Matrix', fontsize=17, pad=20)
plt.gca().xaxis.set_label_position('top')
plt.xlabel('Prediction', fontsize=13)
plt.gca().xaxis.tick_top()

plt.gca().figure.subplots_adjust(bottom=0.2)
plt.gca().figure.text(0.5, 0.05, 'Prediction', ha='center', fontsize=13)
plt.show()

accuracy_score(y_test, y_dtc_pred)

"""**SVM**"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report

svc = SVC(kernel='linear', C = 1.0)
svc.fit(X_train_vec, y_train)

y_svc_pred = svc.predict(X_test_vec)
y_svc_arr = np.array(y_svc_pred)
y_test_arr = np.array(y_test)  # Ensure y_test is also a NumPy array
cm = confusion_matrix(y_test_arr, y_svc_arr)

import seaborn as sns
import matplotlib.pyplot as plt
sns.heatmap(cm,
            annot=True,
            fmt='g',
            xticklabels=['cyberbullying','Not cyberbullying'],
            yticklabels=['cyberbullying','Not cyberbullying'])
plt.ylabel('Actual', fontsize=13)
plt.title('Confusion Matrix', fontsize=17, pad=20)
plt.gca().xaxis.set_label_position('top')
plt.xlabel('Prediction', fontsize=13)
plt.gca().xaxis.tick_top()

plt.gca().figure.subplots_adjust(bottom=0.2)
plt.gca().figure.text(0.5, 0.05, 'Prediction', ha='center', fontsize=13)
plt.show()

accuracy_score(y_test, y_dtc_pred)

"""**K - NN ( K-Nearest Neighbors )**"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train_vec, y_train)

y_knn_pred = svc.predict(X_test_vec)
y_knn_arr = np.array(y_knn_pred)
y_test_arr = np.array(y_test)  # Ensure y_test is also a NumPy array
cm = confusion_matrix(y_test_arr, y_knn_arr)

import seaborn as sns
import matplotlib.pyplot as plt
sns.heatmap(cm,
            annot=True,
            fmt='g',
            xticklabels=['cyberbullying','Not cyberbullying'],
            yticklabels=['cyberbullying','Not cyberbullying'])
plt.ylabel('Actual', fontsize=13)
plt.title('Confusion Matrix', fontsize=17, pad=20)
plt.gca().xaxis.set_label_position('top')
plt.xlabel('Prediction', fontsize=13)
plt.gca().xaxis.tick_top()

plt.gca().figure.subplots_adjust(bottom=0.2)
plt.gca().figure.text(0.5, 0.05, 'Prediction', ha='center', fontsize=13)
plt.show()

accuracy_score(y_test, y_knn_pred)

'''from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Calculate the False Positive Rate (FPR), True Positive Rate (TPR), and thresholds
fpr, tpr, thresholds = roc_curve(y_test_arr, y_knn_arr)

# Calculate the AUC (Area Under the Curve)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()
'''

#pip install pickle-mixin

import pickle

with open("rfc.pkl", "wb") as file:
    pickle.dump(rfc, file)
print("Model saved!")

#from google.colab import files
#files.download("rfc.pkl")