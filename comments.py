# -*- coding: utf-8 -*-
"""comments.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12maRgEnTVf0GGyFUtIh5NUJV5Q6A9KF7
"""

pip install --upgrade google-api-python-client

import googleapiclient.discovery
import pandas as pd
import os
from dotenv import load_dotenv

# Load the .env file
load_dotenv()
# Get the API key
api_key = os.getenv("DEVELOPER_API_KEY")

api_service_name = "youtube"
api_version = "v3"

youtube = googleapiclient.discovery.build(
    api_service_name, api_version, developerKey=DEVELOPER_KEY)


def getcomments(video):
  request = youtube.commentThreads().list(
      part="snippet",
      videoId=video,
      maxResults=500
  )

  comments = []

  response = request.execute()

  # Get the comments from the response.
  for item in response['items']:
      comment = item['snippet']['topLevelComment']['snippet']
      comments.append([
          comment['authorDisplayName'],
          comment['textOriginal'],
      ])

  while (1 == 1):
    try:
     nextPageToken = response['nextPageToken']
    except KeyError:
     break
    nextPageToken = response['nextPageToken']
    # Creating a new request object with the next page token.
    nextRequest = youtube.commentThreads().list(part="snippet", videoId=video, maxResults=100, pageToken=nextPageToken)
    response = nextRequest.execute()
    for item in response['items']:
      comment = item['snippet']['topLevelComment']['snippet']
      comments.append([
          comment['authorDisplayName'],
          comment['textOriginal']
      ])

  df2 = pd.DataFrame(comments, columns=['author', 'text'])
  return df2

df = getcomments('YgQy70_LPS4')
df

df.head(10)
df.to_csv('ytcomments.csv',index=False)

# df = pd.DataFrame()
# for i in ['SiijS_9hPkM','QhaMLN_-F1M']:
#   df2 = getcomments(i)
#   df = pd.concat([df, df2])